{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29d336fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langgraph in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (1.0.6)\n",
      "Requirement already satisfied: langgraph-checkpoint-postgres in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (3.0.3)\n",
      "Requirement already satisfied: psycopg[binary,pool] in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (3.3.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from psycopg[binary,pool]) (2025.2)\n",
      "Requirement already satisfied: psycopg-binary==3.3.2 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from psycopg[binary,pool]) (3.3.2)\n",
      "Requirement already satisfied: psycopg-pool in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from psycopg[binary,pool]) (3.3.0)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langgraph) (1.2.7)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langgraph) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langgraph) (1.0.6)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langgraph) (0.3.3)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langgraph) (2.12.5)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
      "Requirement already satisfied: anyio in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.1->langgraph) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.1->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.7.4->langgraph) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\waseem akram\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.6.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U \"psycopg[binary,pool]\" langgraph langgraph-checkpoint-postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ca5170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import uuid\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_perplexity import ChatPerplexity\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "from langgraph.store.base import BaseStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66911b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a helpful assistant with memory capabilities.\n",
    "If user-specific memory is available, use it to personalize \n",
    "your responses based on what you know about the user.\n",
    "\n",
    "Your goal is to provide relevant, friendly, and tailored \n",
    "assistance that reflects the user’s preferences, context, and past interactions.\n",
    "\n",
    "If the user’s name or relevant personal context is available, always personalize your responses by:\n",
    "    – Always Address the user by name (e.g., \"Sure, Nitish...\") when appropriate\n",
    "    – Referencing known projects, tools, or preferences (e.g., \"your MCP server python based project\")\n",
    "    – Adjusting the tone to feel friendly, natural, and directly aimed at the user\n",
    "\n",
    "Avoid generic phrasing when personalization is possible.\n",
    "\n",
    "Use personalization especially in:\n",
    "    – Greetings and transitions\n",
    "    – Help or guidance tailored to tools and frameworks the user uses\n",
    "    – Follow-up messages that continue from past context\n",
    "\n",
    "Always ensure that personalization is based only on known user details and not assumed.\n",
    "\n",
    "In the end suggest 3 relevant further questions based on the current response and user profile\n",
    "\n",
    "The user’s memory (which may be empty) is provided as: {user_details_content}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11253a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_llm = ChatPerplexity(model=\"sonar-pro\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e74508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryItem(BaseModel):\n",
    "    text: str = Field(description=\"Atomic user memory\")\n",
    "    is_new: bool = Field(description=\"True if new, false if duplicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6145118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryDecision(BaseModel):\n",
    "    should_write: bool\n",
    "    memories: List[MemoryItem] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e1b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_extractor = memory_llm.with_structured_output(MemoryDecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "101b07cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_PROMPT = \"\"\"You are responsible for updating and maintaining accurate user memory.\n",
    "\n",
    "CURRENT USER DETAILS (existing memories):\n",
    "{user_details_content}\n",
    "\n",
    "TASK:\n",
    "- Review the user's latest message.\n",
    "- Extract user-specific info worth storing long-term (identity, stable preferences, ongoing projects/goals).\n",
    "- For each extracted item, set is_new=true ONLY if it adds NEW information compared to CURRENT USER DETAILS.\n",
    "- If it is basically the same meaning as something already present, set is_new=false.\n",
    "- Keep each memory as a short atomic sentence.\n",
    "- No speculation; only facts stated by the user.\n",
    "- If there is nothing memory-worthy, return should_write=false and an empty list.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f0b058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remember_node(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    ns = (\"user\", user_id, \"details\")\n",
    "\n",
    "    # existing memory (all items under namespace)\n",
    "    items = store.search(ns)\n",
    "    existing = \"\\n\".join(it.value.get(\"data\", \"\") for it in items) if items else \"(empty)\"\n",
    "\n",
    "    # latest user message\n",
    "    last_text = state[\"messages\"][-1].content\n",
    "\n",
    "    decision: MemoryDecision = memory_extractor.invoke(\n",
    "        [\n",
    "            SystemMessage(content=MEMORY_PROMPT.format(user_details_content=existing)),\n",
    "            {\"role\": \"user\", \"content\": last_text},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if decision.should_write:\n",
    "        for mem in decision.memories:\n",
    "            if mem.is_new and mem.text.strip():\n",
    "                store.put(ns, str(uuid.uuid4()), {\"data\": mem.text.strip()})\n",
    "\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bf7c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatPerplexity(model=\"sonar-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9107c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    ns = (\"user\", user_id, \"details\")\n",
    "\n",
    "    items = store.search(ns)\n",
    "    user_details = \"\\n\".join(it.value.get(\"data\", \"\") for it in items) if items else \"\"\n",
    "\n",
    "    system_msg = SystemMessage(\n",
    "        content=SYSTEM_PROMPT_TEMPLATE.format(user_details_content=user_details or \"(empty)\")\n",
    "    )\n",
    "\n",
    "    response = chat_llm.invoke([system_msg] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77457bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x24bad491940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"remember\", remember_node)\n",
    "builder.add_node(\"chat\", chat_node)\n",
    "builder.add_edge(START, \"remember\")\n",
    "builder.add_edge(\"remember\", \"chat\")\n",
    "builder.add_edge(\"chat\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8f3d3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Generative AI (GenAI) is a type of artificial intelligence that creates new content—like text, images, videos, or code—based on patterns it learned from existing data.**[1]\n",
      "\n",
      "Think of it like this: GenAI trains on massive amounts of existing content (such as books, images, or code repositories) and learns the underlying patterns. When you give it a prompt, it uses those learned patterns to generate something new that resembles the training data but isn't identical to it.[4] For example, ChatGPT learned from billions of words to predict what words should come next in a sentence, allowing it to write coherent text responses.[3]\n",
      "\n",
      "**Key differences from traditional AI:**[1][2]\n",
      "Traditional AI systems are designed to perform specific, repetitive tasks based on pre-existing data. GenAI, by contrast, can produce original content across many different use cases—from writing emails to generating images to writing code.\n",
      "\n",
      "**How it works:**[2][4]\n",
      "GenAI uses algorithms called large language models (LLMs) and transformer architectures to understand patterns in data. The encoder converts input into meaningful representations, while the decoder generates new output based on those patterns. Because these models train on such enormous datasets and include random elements, they can produce varied and seemingly creative outputs from a single prompt.[5]\n",
      "\n",
      "**Main benefits:**[1]\n",
      "- **Speed**: Completes tasks quickly\n",
      "- **Multiple uses**: Works for coding, writing, summarization, and more\n",
      "- **Scalability**: Handles many users without performance issues\n",
      "\n",
      "**Important limitations:**[2]\n",
      "GenAI can generate misinformation, create biased content, and produce \"hallucinations\" (made-up information presented as fact), raising ethical concerns about responsible deployment.\n",
      "\n",
      "---\n",
      "\n",
      "**Here are 3 relevant follow-up questions for your AI content:**\n",
      "\n",
      "1. How do transformer architectures specifically work in GenAI models like ChatGPT?\n",
      "2. What are the main ethical concerns with GenAI, and how can creators address them in tutorials?\n",
      "3. What are practical applications of GenAI that your YouTube audience could implement or learn about?\n",
      "\n",
      "--- Stored Memories (from Postgres) ---\n",
      "The user's teacher name is Nitesh.\n",
      "The user's name is Waseem-Akram.\n",
      "The user teaches AI on YouTube.\n",
      "The user's name is Nitish.\n"
     ]
    }
   ],
   "source": [
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
    "\n",
    "with PostgresStore.from_conn_string(DB_URI) as store:\n",
    "    # IMPORTANT: run ONCE the first time you use this database\n",
    "    store.setup()\n",
    "\n",
    "    graph = builder.compile(store=store)\n",
    "\n",
    "    config = {\"configurable\": {\"user_id\": \"u1\"}}\n",
    "\n",
    "    graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hi, my name is waseem-akram\"}]}, config)\n",
    "    graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"my teacher name is Nitesh\"}]}, config)\n",
    "    graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"I teach AI on YouTube\"}]}, config)\n",
    "\n",
    "    out = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Explain GenAI simply\"}]}, config)\n",
    "    print(out[\"messages\"][-1].content)\n",
    "\n",
    "    print(\"\\n--- Stored Memories (from Postgres) ---\")\n",
    "    for it in store.search((\"user\", \"u1\", \"details\")):\n",
    "        print(it.value[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e0f802",
   "metadata": {},
   "source": [
    "## Check Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e305c173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user's teacher name is Nitesh.\n",
      "The user's name is Waseem-Akram.\n",
      "The user teaches AI on YouTube.\n",
      "The user's name is Nitish.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.store.postgres import PostgresStore\n",
    "\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
    "\n",
    "with PostgresStore.from_conn_string(DB_URI) as store:\n",
    "    ns = (\"user\", \"u1\", \"details\")\n",
    "    items = store.search(ns)\n",
    "\n",
    "for it in items:\n",
    "    print(it.value[\"data\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
